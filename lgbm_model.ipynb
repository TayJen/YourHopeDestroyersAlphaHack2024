{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTbj6JC0w3YL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import shap\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import optuna\n",
        "\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN64yPVCw59T"
      },
      "outputs": [],
      "source": [
        "sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbOpmSvUw9av"
      },
      "source": [
        "# TYPE DICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eju921naw-t2",
        "jupyter": {
          "source_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "types_dict = {\n",
        "'feature_31': 'int8',\n",
        "'feature_43': 'int8',\n",
        "'feature_61': 'int8',\n",
        "'feature_64': 'int8',\n",
        "'feature_80': 'int8',\n",
        "'feature_83': 'int8',\n",
        "'feature_92': 'int8',\n",
        "'feature_133': 'int8',\n",
        "'feature_143': 'int8',\n",
        "'feature_191': 'int8',\n",
        "'feature_201': 'int8',\n",
        "'feature_209': 'int8',\n",
        "'feature_251': 'int8',\n",
        "'feature_253': 'int8',\n",
        "'feature_299': 'int8',\n",
        "'feature_300': 'int8',\n",
        "'feature_343': 'int8',\n",
        "'feature_382': 'int8',\n",
        "'feature_392': 'int8',\n",
        "'feature_406': 'int8',\n",
        "'feature_423': 'int8',\n",
        "'feature_446': 'int8',\n",
        "'feature_449': 'int8',\n",
        "'feature_459': 'int8',\n",
        "'feature_490': 'int8',\n",
        "'feature_17': 'int8',\n",
        "'feature_21': 'int8',\n",
        "'feature_22': 'int8',\n",
        "'feature_27': 'int8',\n",
        "'feature_166': 'int8',\n",
        "'feature_173': 'int8',\n",
        "'feature_347': 'int8',\n",
        "'feature_405': 'int8',\n",
        "'feature_434': 'int8',\n",
        "'feature_492': 'int8',\n",
        "'target': 'int8',\n",
        "'feature_1': 'float16',\n",
        "'feature_2': 'float16',\n",
        "'feature_3': 'float16',\n",
        "'feature_4': 'float16',\n",
        "'feature_5': 'float16',\n",
        "'feature_6': 'float16',\n",
        "'feature_7': 'float16',\n",
        "'feature_8': 'float16',\n",
        "'feature_9': 'float16',\n",
        "'feature_10': 'float16',\n",
        "'feature_11': 'float16',\n",
        "'feature_12': 'float16',\n",
        "'feature_13': 'float16',\n",
        "'feature_14': 'float16',\n",
        "'feature_15': 'float16',\n",
        "'feature_16': 'float16',\n",
        "'feature_18': 'float16',\n",
        "'feature_19': 'float16',\n",
        "'feature_20': 'float16',\n",
        "'feature_23': 'float16',\n",
        "'feature_24': 'float16',\n",
        "'feature_25': 'float16',\n",
        "'feature_26': 'float16',\n",
        "'feature_28': 'float16',\n",
        "'feature_29': 'float16',\n",
        "'feature_30': 'float16',\n",
        "'feature_32': 'float16',\n",
        "'feature_33': 'float16',\n",
        "'feature_34': 'float16',\n",
        "'feature_35': 'float16',\n",
        "'feature_36': 'float16',\n",
        "'feature_37': 'float16',\n",
        "'feature_38': 'float16',\n",
        "'feature_39': 'float16',\n",
        "'feature_40': 'float16',\n",
        "'feature_41': 'float16',\n",
        "'feature_42': 'float16',\n",
        "'feature_44': 'float16',\n",
        "'feature_45': 'float16',\n",
        "'feature_46': 'float16',\n",
        "'feature_47': 'float16',\n",
        "'feature_48': 'float16',\n",
        "'feature_49': 'float16',\n",
        "'feature_50': 'float16',\n",
        "'feature_51': 'float16',\n",
        "'feature_52': 'float16',\n",
        "'feature_53': 'float16',\n",
        "'feature_54': 'float16',\n",
        "'feature_55': 'float16',\n",
        "'feature_56': 'float16',\n",
        "'feature_57': 'float16',\n",
        "'feature_58': 'float16',\n",
        "'feature_59': 'float16',\n",
        "'feature_60': 'float16',\n",
        "'feature_62': 'float16',\n",
        "'feature_63': 'float16',\n",
        "'feature_65': 'float16',\n",
        "'feature_66': 'float16',\n",
        "'feature_67': 'float16',\n",
        "'feature_68': 'float16',\n",
        "'feature_69': 'float16',\n",
        "'feature_70': 'float16',\n",
        "'feature_71': 'float16',\n",
        "'feature_72': 'float16',\n",
        "'feature_73': 'float16',\n",
        "'feature_74': 'float16',\n",
        "'feature_75': 'float16',\n",
        "'feature_76': 'float16',\n",
        "'feature_77': 'float16',\n",
        "'feature_78': 'float16',\n",
        "'feature_79': 'float16',\n",
        "'feature_81': 'float16',\n",
        "'feature_82': 'float16',\n",
        "'feature_84': 'float16',\n",
        "'feature_85': 'float16',\n",
        "'feature_86': 'float16',\n",
        "'feature_87': 'float16',\n",
        "'feature_88': 'float16',\n",
        "'feature_89': 'float16',\n",
        "'feature_90': 'float16',\n",
        "'feature_91': 'float16',\n",
        "'feature_93': 'float16',\n",
        "'feature_94': 'float16',\n",
        "'feature_95': 'float16',\n",
        "'feature_96': 'float16',\n",
        "'feature_97': 'float16',\n",
        "'feature_98': 'float16',\n",
        "'feature_99': 'float16',\n",
        "'feature_100': 'float16',\n",
        "'feature_101': 'float16',\n",
        "'feature_102': 'float16',\n",
        "'feature_103': 'float16',\n",
        "'feature_104': 'float16',\n",
        "'feature_105': 'float16',\n",
        "'feature_106': 'float16',\n",
        "'feature_107': 'float16',\n",
        "'feature_108': 'float16',\n",
        "'feature_109': 'float16',\n",
        "'feature_110': 'float16',\n",
        "'feature_111': 'float16',\n",
        "'feature_112': 'float16',\n",
        "'feature_113': 'float16',\n",
        "'feature_114': 'float16',\n",
        "'feature_115': 'float16',\n",
        "'feature_116': 'float16',\n",
        "'feature_117': 'float16',\n",
        "'feature_118': 'float16',\n",
        "'feature_119': 'float16',\n",
        "'feature_120': 'float16',\n",
        "'feature_121': 'float16',\n",
        "'feature_122': 'float16',\n",
        "'feature_123': 'float16',\n",
        "'feature_124': 'float16',\n",
        "'feature_125': 'float16',\n",
        "'feature_126': 'float16',\n",
        "'feature_127': 'float16',\n",
        "'feature_128': 'float16',\n",
        "'feature_129': 'float16',\n",
        "'feature_130': 'float16',\n",
        "'feature_131': 'float16',\n",
        "'feature_132': 'float16',\n",
        "'feature_134': 'float16',\n",
        "'feature_135': 'float16',\n",
        "'feature_136': 'float16',\n",
        "'feature_137': 'float16',\n",
        "'feature_138': 'float16',\n",
        "'feature_139': 'float16',\n",
        "'feature_140': 'float16',\n",
        "'feature_141': 'float16',\n",
        "'feature_142': 'float16',\n",
        "'feature_144': 'float16',\n",
        "'feature_145': 'float16',\n",
        "'feature_146': 'float16',\n",
        "'feature_147': 'float16',\n",
        "'feature_148': 'float16',\n",
        "'feature_149': 'float16',\n",
        "'feature_150': 'float16',\n",
        "'feature_151': 'float16',\n",
        "'feature_152': 'float16',\n",
        "'feature_153': 'float16',\n",
        "'feature_154': 'float16',\n",
        "'feature_155': 'float16',\n",
        "'feature_156': 'float16',\n",
        "'feature_157': 'float16',\n",
        "'feature_158': 'float16',\n",
        "'feature_159': 'float16',\n",
        "'feature_160': 'float16',\n",
        "'feature_161': 'float16',\n",
        "'feature_162': 'float16',\n",
        "'feature_163': 'float16',\n",
        "'feature_164': 'float16',\n",
        "'feature_165': 'float16',\n",
        "'feature_167': 'float16',\n",
        "'feature_168': 'float16',\n",
        "'feature_169': 'float16',\n",
        "'feature_170': 'float16',\n",
        "'feature_171': 'float16',\n",
        "'feature_172': 'float16',\n",
        "'feature_174': 'float16',\n",
        "'feature_175': 'float16',\n",
        "'feature_176': 'float16',\n",
        "'feature_177': 'float16',\n",
        "'feature_178': 'float16',\n",
        "'feature_179': 'float16',\n",
        "'feature_180': 'float16',\n",
        "'feature_181': 'float16',\n",
        "'feature_182': 'float16',\n",
        "'feature_183': 'float16',\n",
        "'feature_184': 'float16',\n",
        "'feature_185': 'float16',\n",
        "'feature_186': 'float16',\n",
        "'feature_187': 'float16',\n",
        "'feature_188': 'float16',\n",
        "'feature_189': 'float16',\n",
        "'feature_190': 'float16',\n",
        "'feature_192': 'float16',\n",
        "'feature_193': 'float16',\n",
        "'feature_194': 'float16',\n",
        "'feature_195': 'float16',\n",
        "'feature_196': 'float16',\n",
        "'feature_197': 'float16',\n",
        "'feature_198': 'float16',\n",
        "'feature_199': 'float16',\n",
        "'feature_200': 'float16',\n",
        "'feature_202': 'float16',\n",
        "'feature_203': 'float16',\n",
        "'feature_204': 'float16',\n",
        "'feature_205': 'float16',\n",
        "'feature_206': 'float16',\n",
        "'feature_207': 'float16',\n",
        "'feature_208': 'float16',\n",
        "'feature_210': 'float16',\n",
        "'feature_211': 'float16',\n",
        "'feature_212': 'float16',\n",
        "'feature_213': 'float16',\n",
        "'feature_214': 'float16',\n",
        "'feature_215': 'float16',\n",
        "'feature_216': 'float16',\n",
        "'feature_217': 'float16',\n",
        "'feature_218': 'float16',\n",
        "'feature_219': 'float16',\n",
        "'feature_220': 'float16',\n",
        "'feature_221': 'float16',\n",
        "'feature_222': 'float16',\n",
        "'feature_223': 'float16',\n",
        "'feature_224': 'float16',\n",
        "'feature_225': 'float16',\n",
        "'feature_226': 'float16',\n",
        "'feature_227': 'float16',\n",
        "'feature_228': 'float16',\n",
        "'feature_229': 'float16',\n",
        "'feature_230': 'float16',\n",
        "'feature_231': 'float16',\n",
        "'feature_232': 'float16',\n",
        "'feature_233': 'float16',\n",
        "'feature_234': 'float16',\n",
        "'feature_235': 'float16',\n",
        "'feature_236': 'float16',\n",
        "'feature_237': 'float16',\n",
        "'feature_238': 'float16',\n",
        "'feature_239': 'float16',\n",
        "'feature_240': 'float16',\n",
        "'feature_241': 'float16',\n",
        "'feature_242': 'float16',\n",
        "'feature_243': 'float16',\n",
        "'feature_244': 'float16',\n",
        "'feature_245': 'float16',\n",
        "'feature_246': 'float16',\n",
        "'feature_247': 'float16',\n",
        "'feature_248': 'float16',\n",
        "'feature_249': 'float16',\n",
        "'feature_250': 'float16',\n",
        "'feature_252': 'float16',\n",
        "'feature_254': 'float16',\n",
        "'feature_255': 'float16',\n",
        "'feature_256': 'float16',\n",
        "'feature_257': 'float16',\n",
        "'feature_258': 'float16',\n",
        "'feature_259': 'float16',\n",
        "'feature_260': 'float16',\n",
        "'feature_261': 'float16',\n",
        "'feature_262': 'float16',\n",
        "'feature_263': 'float16',\n",
        "'feature_264': 'float16',\n",
        "'feature_265': 'float16',\n",
        "'feature_266': 'float16',\n",
        "'feature_267': 'float16',\n",
        "'feature_268': 'float16',\n",
        "'feature_269': 'float16',\n",
        "'feature_270': 'float16',\n",
        "'feature_271': 'float16',\n",
        "'feature_272': 'float16',\n",
        "'feature_273': 'float16',\n",
        "'feature_274': 'float16',\n",
        "'feature_275': 'float16',\n",
        "'feature_276': 'float16',\n",
        "'feature_277': 'float16',\n",
        "'feature_278': 'float16',\n",
        "'feature_279': 'float16',\n",
        "'feature_280': 'float16',\n",
        "'feature_281': 'float16',\n",
        "'feature_282': 'float16',\n",
        "'feature_283': 'float16',\n",
        "'feature_284': 'float16',\n",
        "'feature_285': 'float16',\n",
        "'feature_286': 'float16',\n",
        "'feature_287': 'float16',\n",
        "'feature_288': 'float16',\n",
        "'feature_289': 'float16',\n",
        "'feature_290': 'float16',\n",
        "'feature_291': 'float16',\n",
        "'feature_292': 'float16',\n",
        "'feature_293': 'float16',\n",
        "'feature_294': 'float16',\n",
        "'feature_295': 'float16',\n",
        "'feature_296': 'float16',\n",
        "'feature_297': 'float16',\n",
        "'feature_298': 'float16',\n",
        "'feature_301': 'float16',\n",
        "'feature_302': 'float16',\n",
        "'feature_303': 'float16',\n",
        "'feature_304': 'float16',\n",
        "'feature_305': 'float16',\n",
        "'feature_306': 'float16',\n",
        "'feature_307': 'float16',\n",
        "'feature_308': 'float16',\n",
        "'feature_309': 'float16',\n",
        "'feature_310': 'float16',\n",
        "'feature_311': 'float16',\n",
        "'feature_312': 'float16',\n",
        "'feature_313': 'float16',\n",
        "'feature_314': 'float16',\n",
        "'feature_315': 'float16',\n",
        "'feature_316': 'float16',\n",
        "'feature_317': 'float16',\n",
        "'feature_318': 'float16',\n",
        "'feature_319': 'float16',\n",
        "'feature_320': 'float16',\n",
        "'feature_321': 'float16',\n",
        "'feature_322': 'float16',\n",
        "'feature_323': 'float16',\n",
        "'feature_324': 'float16',\n",
        "'feature_325': 'float16',\n",
        "'feature_326': 'float16',\n",
        "'feature_327': 'float16',\n",
        "'feature_328': 'float16',\n",
        "'feature_329': 'float16',\n",
        "'feature_330': 'float16',\n",
        "'feature_331': 'float16',\n",
        "'feature_332': 'float16',\n",
        "'feature_333': 'float16',\n",
        "'feature_334': 'float16',\n",
        "'feature_335': 'float16',\n",
        "'feature_336': 'float16',\n",
        "'feature_337': 'float16',\n",
        "'feature_338': 'float16',\n",
        "'feature_339': 'float16',\n",
        "'feature_340': 'float16',\n",
        "'feature_341': 'float16',\n",
        "'feature_342': 'float16',\n",
        "'feature_344': 'float16',\n",
        "'feature_345': 'float16',\n",
        "'feature_346': 'float16',\n",
        "'feature_348': 'float16',\n",
        "'feature_349': 'float16',\n",
        "'feature_350': 'float16',\n",
        "'feature_351': 'float16',\n",
        "'feature_352': 'float16',\n",
        "'feature_353': 'float16',\n",
        "'feature_354': 'float16',\n",
        "'feature_355': 'float16',\n",
        "'feature_356': 'float16',\n",
        "'feature_357': 'float16',\n",
        "'feature_358': 'float16',\n",
        "'feature_359': 'float16',\n",
        "'feature_360': 'float16',\n",
        "'feature_361': 'float16',\n",
        "'feature_362': 'float16',\n",
        "'feature_363': 'float16',\n",
        "'feature_364': 'float16',\n",
        "'feature_365': 'float16',\n",
        "'feature_366': 'float16',\n",
        "'feature_367': 'float16',\n",
        "'feature_368': 'float16',\n",
        "'feature_369': 'float16',\n",
        "'feature_370': 'float16',\n",
        "'feature_371': 'float16',\n",
        "'feature_372': 'float16',\n",
        "'feature_373': 'float16',\n",
        "'feature_374': 'float16',\n",
        "'feature_375': 'float16',\n",
        "'feature_376': 'float16',\n",
        "'feature_377': 'float16',\n",
        "'feature_378': 'float16',\n",
        "'feature_379': 'float16',\n",
        "'feature_380': 'float16',\n",
        "'feature_381': 'float16',\n",
        "'feature_383': 'float16',\n",
        "'feature_384': 'float16',\n",
        "'feature_385': 'float16',\n",
        "'feature_386': 'float16',\n",
        "'feature_387': 'float16',\n",
        "'feature_388': 'float16',\n",
        "'feature_389': 'float16',\n",
        "'feature_390': 'float16',\n",
        "'feature_391': 'float16',\n",
        "'feature_393': 'float16',\n",
        "'feature_394': 'float16',\n",
        "'feature_395': 'float16',\n",
        "'feature_396': 'float16',\n",
        "'feature_397': 'float16',\n",
        "'feature_398': 'float16',\n",
        "'feature_399': 'float16',\n",
        "'feature_400': 'float16',\n",
        "'feature_401': 'float16',\n",
        "'feature_402': 'float16',\n",
        "'feature_403': 'float16',\n",
        "'feature_404': 'float16',\n",
        "'feature_407': 'float16',\n",
        "'feature_408': 'float16',\n",
        "'feature_409': 'float16',\n",
        "'feature_410': 'float16',\n",
        "'feature_411': 'float16',\n",
        "'feature_412': 'float16',\n",
        "'feature_413': 'float16',\n",
        "'feature_414': 'float16',\n",
        "'feature_415': 'float16',\n",
        "'feature_416': 'float16',\n",
        "'feature_417': 'float16',\n",
        "'feature_418': 'float16',\n",
        "'feature_419': 'float16',\n",
        "'feature_420': 'float16',\n",
        "'feature_421': 'float16',\n",
        "'feature_422': 'float16',\n",
        "'feature_424': 'float16',\n",
        "'feature_425': 'float16',\n",
        "'feature_426': 'float16',\n",
        "'feature_427': 'float16',\n",
        "'feature_428': 'float16',\n",
        "'feature_429': 'float16',\n",
        "'feature_430': 'float16',\n",
        "'feature_431': 'float16',\n",
        "'feature_432': 'float16',\n",
        "'feature_433': 'float16',\n",
        "'feature_435': 'float16',\n",
        "'feature_436': 'float16',\n",
        "'feature_437': 'float16',\n",
        "'feature_438': 'float16',\n",
        "'feature_439': 'float16',\n",
        "'feature_440': 'float16',\n",
        "'feature_441': 'float16',\n",
        "'feature_442': 'float16',\n",
        "'feature_443': 'float16',\n",
        "'feature_444': 'float16',\n",
        "'feature_445': 'float16',\n",
        "'feature_447': 'float16',\n",
        "'feature_448': 'float16',\n",
        "'feature_450': 'float16',\n",
        "'feature_451': 'float16',\n",
        "'feature_452': 'float16',\n",
        "'feature_453': 'float16',\n",
        "'feature_454': 'float16',\n",
        "'feature_455': 'float16',\n",
        "'feature_456': 'float16',\n",
        "'feature_457': 'float16',\n",
        "'feature_458': 'float16',\n",
        "'feature_460': 'float16',\n",
        "'feature_461': 'float16',\n",
        "'feature_462': 'float16',\n",
        "'feature_463': 'float16',\n",
        "'feature_464': 'float16',\n",
        "'feature_465': 'float16',\n",
        "'feature_466': 'float16',\n",
        "'feature_467': 'float16',\n",
        "'feature_468': 'float16',\n",
        "'feature_469': 'float16',\n",
        "'feature_470': 'float16',\n",
        "'feature_471': 'float16',\n",
        "'feature_472': 'float16',\n",
        "'feature_473': 'float16',\n",
        "'feature_474': 'float16',\n",
        "'feature_475': 'float16',\n",
        "'feature_476': 'float16',\n",
        "'feature_477': 'float16',\n",
        "'feature_478': 'float16',\n",
        "'feature_479': 'float16',\n",
        "'feature_480': 'float16',\n",
        "'feature_481': 'float16',\n",
        "'feature_482': 'float16',\n",
        "'feature_483': 'float16',\n",
        "'feature_484': 'float16',\n",
        "'feature_485': 'float16',\n",
        "'feature_486': 'float16',\n",
        "'feature_487': 'float16',\n",
        "'feature_488': 'float16',\n",
        "'feature_489': 'float16',\n",
        "'feature_491': 'float16',\n",
        "'feature_493': 'float16',\n",
        "'feature_494': 'float16',\n",
        "'feature_495': 'float16',\n",
        "'feature_496': 'float16',\n",
        "'feature_497': 'float16',\n",
        "'feature_498': 'float16',\n",
        "'feature_499': 'float16',\n",
        "'feature_500': 'float16'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDRxnkeUxADO"
      },
      "source": [
        "# UPLOAD DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем данные"
      ],
      "metadata": {
        "id": "7oXI3uD_0xPc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNl1YKD6xJLt"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train_1.csv', dtype=types_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2x4UUVZxKxA"
      },
      "outputs": [],
      "source": [
        "for i in range(2, 11):\n",
        "    train = pd.concat([train, pd.read_csv(f'train_{i}.csv', dtype=types_dict)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIYNExATyO93"
      },
      "source": [
        "# DATA PREP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применяем предобработку данных из ноутбука eda_and_data_prep"
      ],
      "metadata": {
        "id": "cUER1rp306Bw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzJwoJGcxM7y"
      },
      "outputs": [],
      "source": [
        "train = train.drop(['smpl', 'id'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tyXRnhWMxQs3",
        "outputId": "9460b1ee-70a5-44d8-d043-ad1343ae1697"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_491</th>\n",
              "      <th>feature_492</th>\n",
              "      <th>feature_493</th>\n",
              "      <th>feature_494</th>\n",
              "      <th>feature_495</th>\n",
              "      <th>feature_496</th>\n",
              "      <th>feature_497</th>\n",
              "      <th>feature_498</th>\n",
              "      <th>feature_499</th>\n",
              "      <th>feature_500</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.372314</td>\n",
              "      <td>1.500977</td>\n",
              "      <td>2.132812</td>\n",
              "      <td>-0.957520</td>\n",
              "      <td>-0.119019</td>\n",
              "      <td>0.122925</td>\n",
              "      <td>0.151001</td>\n",
              "      <td>0.506836</td>\n",
              "      <td>-0.839355</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.254883</td>\n",
              "      <td>0</td>\n",
              "      <td>0.803711</td>\n",
              "      <td>-1.017578</td>\n",
              "      <td>-0.520996</td>\n",
              "      <td>0.646973</td>\n",
              "      <td>1.454102</td>\n",
              "      <td>-0.833496</td>\n",
              "      <td>0.184082</td>\n",
              "      <td>-0.438232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.382324</td>\n",
              "      <td>0.962402</td>\n",
              "      <td>-0.192505</td>\n",
              "      <td>-1.019531</td>\n",
              "      <td>-1.330078</td>\n",
              "      <td>-0.100159</td>\n",
              "      <td>-1.130859</td>\n",
              "      <td>-1.172852</td>\n",
              "      <td>-1.790039</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.884277</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.643555</td>\n",
              "      <td>-1.264648</td>\n",
              "      <td>-1.523438</td>\n",
              "      <td>0.604980</td>\n",
              "      <td>0.491943</td>\n",
              "      <td>-0.003685</td>\n",
              "      <td>0.469727</td>\n",
              "      <td>-1.094727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.472412</td>\n",
              "      <td>-0.695312</td>\n",
              "      <td>0.538086</td>\n",
              "      <td>-0.032990</td>\n",
              "      <td>-0.364746</td>\n",
              "      <td>-0.441895</td>\n",
              "      <td>-0.035950</td>\n",
              "      <td>-0.921387</td>\n",
              "      <td>0.746582</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.322754</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.496826</td>\n",
              "      <td>-0.051941</td>\n",
              "      <td>0.743164</td>\n",
              "      <td>-1.395508</td>\n",
              "      <td>0.147949</td>\n",
              "      <td>-0.007553</td>\n",
              "      <td>-0.981445</td>\n",
              "      <td>0.270996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.512207</td>\n",
              "      <td>-1.232422</td>\n",
              "      <td>0.555176</td>\n",
              "      <td>1.457031</td>\n",
              "      <td>1.435547</td>\n",
              "      <td>0.168579</td>\n",
              "      <td>-0.628906</td>\n",
              "      <td>0.249756</td>\n",
              "      <td>1.475586</td>\n",
              "      <td>...</td>\n",
              "      <td>0.976562</td>\n",
              "      <td>0</td>\n",
              "      <td>1.182617</td>\n",
              "      <td>-0.178711</td>\n",
              "      <td>1.467773</td>\n",
              "      <td>-0.791016</td>\n",
              "      <td>0.000645</td>\n",
              "      <td>0.674805</td>\n",
              "      <td>0.803223</td>\n",
              "      <td>1.037109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1.488281</td>\n",
              "      <td>-0.164429</td>\n",
              "      <td>-1.197266</td>\n",
              "      <td>1.548828</td>\n",
              "      <td>0.952637</td>\n",
              "      <td>1.144531</td>\n",
              "      <td>-0.963867</td>\n",
              "      <td>0.031891</td>\n",
              "      <td>1.262695</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.655273</td>\n",
              "      <td>0</td>\n",
              "      <td>1.076172</td>\n",
              "      <td>-0.555664</td>\n",
              "      <td>1.249023</td>\n",
              "      <td>-0.485840</td>\n",
              "      <td>0.458740</td>\n",
              "      <td>-0.444580</td>\n",
              "      <td>-0.333740</td>\n",
              "      <td>0.380127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449049</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.276367</td>\n",
              "      <td>-0.344482</td>\n",
              "      <td>0.609863</td>\n",
              "      <td>-0.214722</td>\n",
              "      <td>-0.345947</td>\n",
              "      <td>0.772461</td>\n",
              "      <td>-0.074585</td>\n",
              "      <td>2.414062</td>\n",
              "      <td>2.994141</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>2.474609</td>\n",
              "      <td>1.364258</td>\n",
              "      <td>2.972656</td>\n",
              "      <td>1.421875</td>\n",
              "      <td>-0.688965</td>\n",
              "      <td>1.313477</td>\n",
              "      <td>0.201904</td>\n",
              "      <td>0.562988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449050</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.270996</td>\n",
              "      <td>-1.203125</td>\n",
              "      <td>-0.068298</td>\n",
              "      <td>0.587891</td>\n",
              "      <td>0.373535</td>\n",
              "      <td>1.384766</td>\n",
              "      <td>-0.474854</td>\n",
              "      <td>1.772461</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.808594</td>\n",
              "      <td>0</td>\n",
              "      <td>3.041016</td>\n",
              "      <td>0.568359</td>\n",
              "      <td>0.613281</td>\n",
              "      <td>-1.115234</td>\n",
              "      <td>2.103516</td>\n",
              "      <td>1.550781</td>\n",
              "      <td>-0.843262</td>\n",
              "      <td>-0.333740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449051</th>\n",
              "      <td>0</td>\n",
              "      <td>0.616211</td>\n",
              "      <td>-1.386719</td>\n",
              "      <td>1.023438</td>\n",
              "      <td>-1.549805</td>\n",
              "      <td>1.183594</td>\n",
              "      <td>3.136719</td>\n",
              "      <td>1.113281</td>\n",
              "      <td>3.097656</td>\n",
              "      <td>2.240234</td>\n",
              "      <td>...</td>\n",
              "      <td>3.128906</td>\n",
              "      <td>0</td>\n",
              "      <td>2.220703</td>\n",
              "      <td>-0.923340</td>\n",
              "      <td>2.207031</td>\n",
              "      <td>3.003906</td>\n",
              "      <td>0.151123</td>\n",
              "      <td>1.565430</td>\n",
              "      <td>-0.528809</td>\n",
              "      <td>-0.351562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449052</th>\n",
              "      <td>0</td>\n",
              "      <td>-2.146484</td>\n",
              "      <td>-1.831055</td>\n",
              "      <td>0.590820</td>\n",
              "      <td>0.657227</td>\n",
              "      <td>-1.164062</td>\n",
              "      <td>0.397461</td>\n",
              "      <td>0.155518</td>\n",
              "      <td>0.782715</td>\n",
              "      <td>-0.567383</td>\n",
              "      <td>...</td>\n",
              "      <td>1.198242</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.649902</td>\n",
              "      <td>0.685059</td>\n",
              "      <td>-0.877441</td>\n",
              "      <td>-0.434326</td>\n",
              "      <td>-1.021484</td>\n",
              "      <td>-0.267090</td>\n",
              "      <td>-0.418457</td>\n",
              "      <td>-0.224731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449053</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.234375</td>\n",
              "      <td>-0.114807</td>\n",
              "      <td>-0.029282</td>\n",
              "      <td>-0.603027</td>\n",
              "      <td>-0.322510</td>\n",
              "      <td>-0.583008</td>\n",
              "      <td>-0.504883</td>\n",
              "      <td>-0.690430</td>\n",
              "      <td>-0.759766</td>\n",
              "      <td>...</td>\n",
              "      <td>1.490234</td>\n",
              "      <td>0</td>\n",
              "      <td>0.820801</td>\n",
              "      <td>-1.223633</td>\n",
              "      <td>-1.052734</td>\n",
              "      <td>1.424805</td>\n",
              "      <td>0.794922</td>\n",
              "      <td>-1.684570</td>\n",
              "      <td>-0.432129</td>\n",
              "      <td>-0.189331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4490468 rows × 501 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        target  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0            0   0.372314   1.500977   2.132812  -0.957520  -0.119019   \n",
              "1            0   0.382324   0.962402  -0.192505  -1.019531  -1.330078   \n",
              "2            0   0.472412  -0.695312   0.538086  -0.032990  -0.364746   \n",
              "3            0   0.512207  -1.232422   0.555176   1.457031   1.435547   \n",
              "4            0   1.488281  -0.164429  -1.197266   1.548828   0.952637   \n",
              "...        ...        ...        ...        ...        ...        ...   \n",
              "449049       1  -0.276367  -0.344482   0.609863  -0.214722  -0.345947   \n",
              "449050       0  -0.270996  -1.203125  -0.068298   0.587891   0.373535   \n",
              "449051       0   0.616211  -1.386719   1.023438  -1.549805   1.183594   \n",
              "449052       0  -2.146484  -1.831055   0.590820   0.657227  -1.164062   \n",
              "449053       0  -1.234375  -0.114807  -0.029282  -0.603027  -0.322510   \n",
              "\n",
              "        feature_6  feature_7  feature_8  feature_9  ...  feature_491  \\\n",
              "0        0.122925   0.151001   0.506836  -0.839355  ...    -1.254883   \n",
              "1       -0.100159  -1.130859  -1.172852  -1.790039  ...    -0.884277   \n",
              "2       -0.441895  -0.035950  -0.921387   0.746582  ...    -0.322754   \n",
              "3        0.168579  -0.628906   0.249756   1.475586  ...     0.976562   \n",
              "4        1.144531  -0.963867   0.031891   1.262695  ...    -1.655273   \n",
              "...           ...        ...        ...        ...  ...          ...   \n",
              "449049   0.772461  -0.074585   2.414062   2.994141  ...     2.000000   \n",
              "449050   1.384766  -0.474854   1.772461   0.625000  ...     0.808594   \n",
              "449051   3.136719   1.113281   3.097656   2.240234  ...     3.128906   \n",
              "449052   0.397461   0.155518   0.782715  -0.567383  ...     1.198242   \n",
              "449053  -0.583008  -0.504883  -0.690430  -0.759766  ...     1.490234   \n",
              "\n",
              "        feature_492  feature_493  feature_494  feature_495  feature_496  \\\n",
              "0                 0     0.803711    -1.017578    -0.520996     0.646973   \n",
              "1                 0    -1.643555    -1.264648    -1.523438     0.604980   \n",
              "2                 0    -0.496826    -0.051941     0.743164    -1.395508   \n",
              "3                 0     1.182617    -0.178711     1.467773    -0.791016   \n",
              "4                 0     1.076172    -0.555664     1.249023    -0.485840   \n",
              "...             ...          ...          ...          ...          ...   \n",
              "449049            0     2.474609     1.364258     2.972656     1.421875   \n",
              "449050            0     3.041016     0.568359     0.613281    -1.115234   \n",
              "449051            0     2.220703    -0.923340     2.207031     3.003906   \n",
              "449052            0    -0.649902     0.685059    -0.877441    -0.434326   \n",
              "449053            0     0.820801    -1.223633    -1.052734     1.424805   \n",
              "\n",
              "        feature_497  feature_498  feature_499  feature_500  \n",
              "0          1.454102    -0.833496     0.184082    -0.438232  \n",
              "1          0.491943    -0.003685     0.469727    -1.094727  \n",
              "2          0.147949    -0.007553    -0.981445     0.270996  \n",
              "3          0.000645     0.674805     0.803223     1.037109  \n",
              "4          0.458740    -0.444580    -0.333740     0.380127  \n",
              "...             ...          ...          ...          ...  \n",
              "449049    -0.688965     1.313477     0.201904     0.562988  \n",
              "449050     2.103516     1.550781    -0.843262    -0.333740  \n",
              "449051     0.151123     1.565430    -0.528809    -0.351562  \n",
              "449052    -1.021484    -0.267090    -0.418457    -0.224731  \n",
              "449053     0.794922    -1.684570    -0.432129    -0.189331  \n",
              "\n",
              "[4490468 rows x 501 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CYzuGiMxRIY",
        "outputId": "bbf6443a-6a06-4d4c-f13c-90d3883791e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4490468 entries, 0 to 449053\n",
            "Columns: 501 entries, target to feature_500\n",
            "dtypes: float16(465), int8(36)\n",
            "memory usage: 4.1 GB\n"
          ]
        }
      ],
      "source": [
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HzybSLUxbF8"
      },
      "outputs": [],
      "source": [
        "cat_features = ['feature_31','feature_61','feature_64','feature_80','feature_83','feature_92','feature_133','feature_143','feature_201','feature_209','feature_251','feature_253',\n",
        "                'feature_300','feature_343','feature_382','feature_406','feature_423','feature_446','feature_449','feature_459','feature_490']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhhOfHoHJsyo"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = ['feature_17', 'feature_21', 'feature_27', 'feature_166', 'feature_173', 'feature_299', 'feature_424', 'feature_434', 'feature_191'] # duplicates and high correlated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGvfS5G8xn-6"
      },
      "outputs": [],
      "source": [
        "train = train.drop(cols_to_drop, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYWMfu1Jxpc6"
      },
      "outputs": [],
      "source": [
        "def preprocess_83(x):\n",
        "    if x in [31, 14, 33, 27, 34, 15, 17, 32, 36, 30, 18]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_133(x):\n",
        "    if x in [11, 15, 8, 17, 19, 9, 7, 10, 12, 6, 16, 18, 20]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_201(x):\n",
        "    if x in [22, 14]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_251(x):\n",
        "    if x in [17, 7, 20, 13, 22, 11, 19, 10, 21, 12, 16, 24, 15, 23]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_253(x):\n",
        "    if x in [31, 35, 34, 29, 27, 26, 19, 25, 32, 30]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_343(x):\n",
        "    if x in [29, 14, 15, 30, 32, 25, 31, 28, 21, 34, 6, 11, 13]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_382(x):\n",
        "    if x in [12, 11]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_406(x):\n",
        "    if x in [10, 14, 17, 11, 12, 15, 3]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_423(x):\n",
        "    if x in [11, 14, 12, 13, 10, 8, 18, 6, 15, 17, 9]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_449(x):\n",
        "    if x in [15, 14, 12, 13, 10]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def preprocess_490(x):\n",
        "    if x in [58, 53, 55]:\n",
        "        return -1\n",
        "    else:\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zMxki_fx-sb"
      },
      "outputs": [],
      "source": [
        "y = train['target']\n",
        "train = train.drop('target', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3dlNiCLyADc"
      },
      "outputs": [],
      "source": [
        "train['feature_83'] =  train['feature_83'].apply(preprocess_83).astype('int8')\n",
        "train['feature_133'] = train['feature_133'].apply(preprocess_133).astype('int8')\n",
        "train['feature_201'] = train['feature_201'].apply(preprocess_201).astype('int8')\n",
        "train['feature_251'] = train['feature_251'].apply(preprocess_251).astype('int8')\n",
        "train['feature_253'] = train['feature_253'].apply(preprocess_253).astype('int8')\n",
        "train['feature_343'] = train['feature_343'].apply(preprocess_343).astype('int8')\n",
        "train['feature_382'] = train['feature_382'].apply(preprocess_382).astype('int8')\n",
        "train['feature_406'] = train['feature_406'].apply(preprocess_406).astype('int8')\n",
        "train['feature_423'] = train['feature_423'].apply(preprocess_423).astype('int8')\n",
        "train['feature_449'] = train['feature_449'].apply(preprocess_449).astype('int8')\n",
        "train['feature_490'] = train['feature_490'].apply(preprocess_490).astype('int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pqGa78cyDIG",
        "outputId": "4cd62ae5-c0aa-4ae0-8fec-4dd35eaf3035"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4490468, 491)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFQGIVoWyBej"
      },
      "outputs": [],
      "source": [
        "train = pd.get_dummies(train, columns=cat_features, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E12ro_AVyDpm",
        "outputId": "8f7f6ef2-9290-43bd-8d7c-da5bd761c2b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4490468, 725)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY139C9cxDhV"
      },
      "outputs": [],
      "source": [
        "no_cols = ['feature_83_4', 'feature_83_7', 'feature_83_8', 'feature_83_12', 'feature_83_13', 'feature_83_20', 'feature_83_22',\n",
        "           'feature_83_24', 'feature_133_4', 'feature_251_3', 'feature_251_5', 'feature_251_6', 'feature_251_9', 'feature_343_3',\n",
        "           'feature_343_8', 'feature_343_12', 'feature_343_18', 'feature_343_19', 'feature_406_6', 'feature_446_7', 'feature_459_2'] # this cols are not presented in test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wmeasgVyF73"
      },
      "outputs": [],
      "source": [
        "zero_weight_cols = ['feature_490_24','feature_253_9','feature_83_1','feature_406_4','feature_64_3','feature_31_2','feature_253_21','feature_490_50',\n",
        "                    'feature_61_2','feature_253_17','feature_253_11','feature_490_43','feature_490_40','feature_64_2','feature_300_5','feature_490_18',\n",
        "                    'feature_83_35','feature_446_3','feature_382_4','feature_382_6','feature_446_6','feature_446_4','feature_423_5','feature_423_4',\n",
        "                    'feature_382_8','feature_406_9','feature_382_9','feature_406_7','feature_251_4','feature_449_7','feature_490_15','feature_343_23',\n",
        "                    'feature_490_14','feature_92_8','feature_22','feature_92_9','feature_490_5','feature_343_35','feature_490_4','feature_92_12',\n",
        "                    'feature_343_26','feature_343_33','feature_143_5'] # by shap catboost and lgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieWpSHyPyF73"
      },
      "outputs": [],
      "source": [
        "weak_cols = ['feature_490_13','feature_490_46','feature_201_5','feature_490_48','feature_201_15','feature_490_35','feature_343_17',\n",
        "             'feature_490_54','feature_251_8','feature_61_3','feature_406_5','feature_253_12','feature_343_27','feature_92_11',\n",
        "             'feature_382_13','feature_253_18','feature_83_10','feature_253_20','feature_201_10','feature_143_7','feature_343_24',\n",
        "             'feature_201_18','feature_83_6','feature_253_23','feature_253_13','feature_253_22','feature_253_28','feature_92_13',\n",
        "             'feature_406_16','feature_253_7','feature_201_8','feature_343_16','feature_83_19','feature_83_28'] # by shap catboost and lgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_KewJZV9MVd"
      },
      "outputs": [],
      "source": [
        "train = train.drop(no_cols+zero_weight_cols+weak_cols, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzoR0bYpuNME",
        "outputId": "0ade6421-0d0d-4bb6-81f3-08934c1bf571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4490468, 627)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-pzcgub-hp7"
      },
      "outputs": [],
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(train, y, test_size=0.1, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUu0gDycWpeI"
      },
      "source": [
        "# MODELING"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подберем лучшую модель с помощью optuna"
      ],
      "metadata": {
        "id": "YFM15xHD1Ow7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2vubi-8yF73"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    space = {\n",
        "        'max_depth': -1,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.03, log=True),\n",
        "        'num_leaves': trial.suggest_int(\"num_leaves\", 31, 310),\n",
        "        'iterations': 15800,\n",
        "        'early_stopping_rounds': 50,\n",
        "        'random_state': 666,\n",
        "        'verbose': -1,\n",
        "        'objective': 'binary',\n",
        "        'device': 'gpu'\n",
        "    }\n",
        "\n",
        "    w=[]\n",
        "    best_iter = []\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=666)\n",
        "\n",
        "    for train_index, val_index in skf.split(train, y):\n",
        "\n",
        "        x_train_1, x_valid_1 = train.iloc[train_index, :], train.iloc[val_index, :]\n",
        "        y_train_1, y_valid_1 = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "        model = LGBMClassifier(**space)\n",
        "\n",
        "        model.fit(x_train_1, y_train_1, eval_set=(x_valid_1, y_valid_1), eval_metric='auc')\n",
        "\n",
        "        w.append(model.best_score_['valid_0']['auc'])\n",
        "        best_iter.append(model.best_iteration_)\n",
        "\n",
        "    nrounds.append(np.mean(best_iter))\n",
        "\n",
        "    res = np.mean(w)\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "RkRX6HxHyF73",
        "outputId": "2eeb173f-dcb5-4836-c330-e5d58f0b18d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-11-12 01:15:40,115] A new study created in memory with name: no-name-954ec6a7-b0e8-4232-a446-b8d9cc87bc55\n",
            "[I 2024-11-12 01:21:30,814] Trial 0 finished with value: 0.8418504892229819 and parameters: {'learning_rate': 0.02158705700818291, 'num_leaves': 267}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 01:27:09,448] Trial 1 finished with value: 0.8410291142593236 and parameters: {'learning_rate': 0.021027099452246237, 'num_leaves': 234}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 01:31:14,347] Trial 2 finished with value: 0.8355436501851603 and parameters: {'learning_rate': 0.028442044689389632, 'num_leaves': 34}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 01:35:23,023] Trial 3 finished with value: 0.8260994024180276 and parameters: {'learning_rate': 0.015751846891084536, 'num_leaves': 44}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 01:40:31,873] Trial 4 finished with value: 0.8297334920354512 and parameters: {'learning_rate': 0.011160355803181485, 'num_leaves': 173}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 01:46:04,360] Trial 5 finished with value: 0.8331847564230145 and parameters: {'learning_rate': 0.012460697619083064, 'num_leaves': 239}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 01:51:44,353] Trial 6 finished with value: 0.8328735798802119 and parameters: {'learning_rate': 0.012360409937206893, 'num_leaves': 227}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 01:57:32,174] Trial 7 finished with value: 0.835107637927555 and parameters: {'learning_rate': 0.013800834943496805, 'num_leaves': 247}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 02:01:53,918] Trial 8 finished with value: 0.8209779103870185 and parameters: {'learning_rate': 0.010056284133808546, 'num_leaves': 62}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 02:06:35,470] Trial 9 finished with value: 0.8264857988160819 and parameters: {'learning_rate': 0.011296355600982083, 'num_leaves': 100}. Best is trial 0 with value: 0.8418504892229819.\n",
            "[I 2024-11-12 02:12:36,057] Trial 10 finished with value: 0.8419029969543917 and parameters: {'learning_rate': 0.020911204607756927, 'num_leaves': 310}. Best is trial 10 with value: 0.8419029969543917.\n",
            "[I 2024-11-12 02:18:37,283] Trial 11 finished with value: 0.8417327901453406 and parameters: {'learning_rate': 0.020651246297940823, 'num_leaves': 305}. Best is trial 10 with value: 0.8419029969543917.\n",
            "[I 2024-11-12 02:24:27,261] Trial 12 finished with value: 0.8431808131720528 and parameters: {'learning_rate': 0.02304158837298533, 'num_leaves': 303}. Best is trial 12 with value: 0.8431808131720528.\n",
            "[I 2024-11-12 02:30:18,539] Trial 13 finished with value: 0.8451989693028699 and parameters: {'learning_rate': 0.02693459575310726, 'num_leaves': 303}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 02:35:26,840] Trial 14 finished with value: 0.843707640378447 and parameters: {'learning_rate': 0.027366525863758522, 'num_leaves': 180}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 02:40:31,743] Trial 15 finished with value: 0.8426322886661424 and parameters: {'learning_rate': 0.0256554339095831, 'num_leaves': 171}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 02:45:18,793] Trial 16 finished with value: 0.8436199741494133 and parameters: {'learning_rate': 0.02987396329728189, 'num_leaves': 124}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 02:50:33,924] Trial 17 finished with value: 0.8384656204328363 and parameters: {'learning_rate': 0.018515327902336925, 'num_leaves': 197}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 02:55:24,487] Trial 18 finished with value: 0.8414787136862156 and parameters: {'learning_rate': 0.02556309200840097, 'num_leaves': 132}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:00:40,953] Trial 19 finished with value: 0.8431237899341613 and parameters: {'learning_rate': 0.02564393528227336, 'num_leaves': 202}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:06:22,012] Trial 20 finished with value: 0.839261997890372 and parameters: {'learning_rate': 0.01777940456915033, 'num_leaves': 273}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:11:05,264] Trial 21 finished with value: 0.8430865444561395 and parameters: {'learning_rate': 0.029945182821514957, 'num_leaves': 110}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:15:58,126] Trial 22 finished with value: 0.8427983267104672 and parameters: {'learning_rate': 0.027382773014567683, 'num_leaves': 138}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:20:26,474] Trial 23 finished with value: 0.8380134241936197 and parameters: {'learning_rate': 0.023977243995687122, 'num_leaves': 85}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:25:17,228] Trial 24 finished with value: 0.8442995505587039 and parameters: {'learning_rate': 0.02995239828316936, 'num_leaves': 142}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:30:09,788] Trial 25 finished with value: 0.843115394642337 and parameters: {'learning_rate': 0.02751672869608501, 'num_leaves': 148}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:35:24,471] Trial 26 finished with value: 0.8421906707655011 and parameters: {'learning_rate': 0.02369058301864219, 'num_leaves': 209}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:40:24,806] Trial 27 finished with value: 0.8351588047197659 and parameters: {'learning_rate': 0.0157436000648356, 'num_leaves': 163}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:44:43,712] Trial 28 finished with value: 0.8390313938898173 and parameters: {'learning_rate': 0.026733435863359745, 'num_leaves': 72}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:50:20,549] Trial 29 finished with value: 0.8403140811836497 and parameters: {'learning_rate': 0.01916669413451904, 'num_leaves': 273}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 03:55:31,217] Trial 30 finished with value: 0.8415032676363717 and parameters: {'learning_rate': 0.02303762217781258, 'num_leaves': 192}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 04:00:12,955] Trial 31 finished with value: 0.8434954284198877 and parameters: {'learning_rate': 0.029681565634501927, 'num_leaves': 120}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 04:05:08,716] Trial 32 finished with value: 0.8444200657133116 and parameters: {'learning_rate': 0.029567268500687662, 'num_leaves': 155}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 04:10:05,699] Trial 33 finished with value: 0.8433185196555211 and parameters: {'learning_rate': 0.027798437790015524, 'num_leaves': 152}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 04:15:12,361] Trial 34 finished with value: 0.8421889795387567 and parameters: {'learning_rate': 0.024713012157167785, 'num_leaves': 183}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 04:19:44,275] Trial 35 finished with value: 0.8372403701526425 and parameters: {'learning_rate': 0.02217298353986223, 'num_leaves': 95}. Best is trial 13 with value: 0.8451989693028699.\n",
            "[I 2024-11-12 04:25:03,846] Trial 36 finished with value: 0.8452096218649698 and parameters: {'learning_rate': 0.028911010045629442, 'num_leaves': 219}. Best is trial 36 with value: 0.8452096218649698.\n",
            "[I 2024-11-12 04:30:24,258] Trial 37 finished with value: 0.8451205714118506 and parameters: {'learning_rate': 0.028718902788556048, 'num_leaves': 224}. Best is trial 36 with value: 0.8452096218649698.\n",
            "[I 2024-11-12 04:35:53,454] Trial 38 finished with value: 0.8440870642828342 and parameters: {'learning_rate': 0.025953792293079325, 'num_leaves': 253}. Best is trial 36 with value: 0.8452096218649698.\n",
            "[I 2024-11-12 04:41:14,820] Trial 39 finished with value: 0.8370545952099029 and parameters: {'learning_rate': 0.01627302772702814, 'num_leaves': 221}. Best is trial 36 with value: 0.8452096218649698.\n",
            "[I 2024-11-12 04:46:32,957] Trial 40 finished with value: 0.8451592637798658 and parameters: {'learning_rate': 0.028827602700918088, 'num_leaves': 217}. Best is trial 36 with value: 0.8452096218649698.\n",
            "[I 2024-11-12 04:52:11,706] Trial 41 finished with value: 0.8459971899188664 and parameters: {'learning_rate': 0.028908925216381047, 'num_leaves': 289}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 04:57:49,780] Trial 42 finished with value: 0.84582923711692 and parameters: {'learning_rate': 0.02831622213595101, 'num_leaves': 285}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:03:29,298] Trial 43 finished with value: 0.8456506431843313 and parameters: {'learning_rate': 0.028150291678675436, 'num_leaves': 288}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:09:09,662] Trial 44 finished with value: 0.843758297967393 and parameters: {'learning_rate': 0.024593169621172608, 'num_leaves': 291}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:14:51,013] Trial 45 finished with value: 0.8422848607453968 and parameters: {'learning_rate': 0.021825818561982555, 'num_leaves': 286}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:20:30,378] Trial 46 finished with value: 0.8448272923957936 and parameters: {'learning_rate': 0.0264536061063192, 'num_leaves': 289}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:26:00,818] Trial 47 finished with value: 0.8453862139252213 and parameters: {'learning_rate': 0.028090838924251384, 'num_leaves': 258}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:31:31,782] Trial 48 finished with value: 0.8356592940918685 and parameters: {'learning_rate': 0.014149349209978184, 'num_leaves': 254}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:36:56,441] Trial 49 finished with value: 0.845214638186175 and parameters: {'learning_rate': 0.028233362346693668, 'num_leaves': 243}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:42:20,268] Trial 50 finished with value: 0.8450554438237585 and parameters: {'learning_rate': 0.02807965630922983, 'num_leaves': 238}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:47:53,547] Trial 51 finished with value: 0.8455389802180273 and parameters: {'learning_rate': 0.0283190055231431, 'num_leaves': 269}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:53:26,428] Trial 52 finished with value: 0.8436799148034353 and parameters: {'learning_rate': 0.024867816049396144, 'num_leaves': 264}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 05:59:02,156] Trial 53 finished with value: 0.844720862540353 and parameters: {'learning_rate': 0.026491072393596, 'num_leaves': 278}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:04:33,499] Trial 54 finished with value: 0.8453926136371326 and parameters: {'learning_rate': 0.028158056180648226, 'num_leaves': 265}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:10:17,228] Trial 55 finished with value: 0.8412639992767271 and parameters: {'learning_rate': 0.019984544913882126, 'num_leaves': 298}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:15:49,132] Trial 56 finished with value: 0.8439238667403636 and parameters: {'learning_rate': 0.025396124098614532, 'num_leaves': 262}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:21:26,281] Trial 57 finished with value: 0.8428882170572848 and parameters: {'learning_rate': 0.022946347249725427, 'num_leaves': 278}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:27:12,136] Trial 58 finished with value: 0.8452895905836131 and parameters: {'learning_rate': 0.026921599828207996, 'num_leaves': 309}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:32:42,525] Trial 59 finished with value: 0.8454564351490024 and parameters: {'learning_rate': 0.02818379138767415, 'num_leaves': 257}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:38:24,723] Trial 60 finished with value: 0.8435631598528742 and parameters: {'learning_rate': 0.02395736186971371, 'num_leaves': 295}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:43:54,900] Trial 61 finished with value: 0.8452390667125401 and parameters: {'learning_rate': 0.028040617496236552, 'num_leaves': 257}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:49:33,389] Trial 62 finished with value: 0.8445510311973534 and parameters: {'learning_rate': 0.02619209616737931, 'num_leaves': 282}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 06:54:56,607] Trial 63 finished with value: 0.8445479145111202 and parameters: {'learning_rate': 0.027210322207782738, 'num_leaves': 232}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 07:00:30,103] Trial 64 finished with value: 0.8457729303105547 and parameters: {'learning_rate': 0.0285156494384289, 'num_leaves': 272}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 07:06:04,088] Trial 65 finished with value: 0.8458376359211073 and parameters: {'learning_rate': 0.02908706703911379, 'num_leaves': 272}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 07:11:39,747] Trial 66 finished with value: 0.8459694734256118 and parameters: {'learning_rate': 0.02897435318464369, 'num_leaves': 271}. Best is trial 41 with value: 0.8459971899188664.\n",
            "[I 2024-11-12 07:17:15,581] Trial 67 finished with value: 0.8461116172832849 and parameters: {'learning_rate': 0.029227488324533084, 'num_leaves': 273}. Best is trial 67 with value: 0.8461116172832849.\n",
            "[I 2024-11-12 07:22:57,600] Trial 68 finished with value: 0.8463841042114222 and parameters: {'learning_rate': 0.029280210002902287, 'num_leaves': 300}. Best is trial 68 with value: 0.8463841042114222.\n",
            "[I 2024-11-12 07:28:39,459] Trial 69 finished with value: 0.8463632690965776 and parameters: {'learning_rate': 0.02933595056139172, 'num_leaves': 300}. Best is trial 68 with value: 0.8463841042114222.\n",
            "[I 2024-11-12 07:34:21,263] Trial 70 finished with value: 0.8467391243973463 and parameters: {'learning_rate': 0.02997094014198667, 'num_leaves': 301}. Best is trial 70 with value: 0.8467391243973463.\n",
            "[I 2024-11-12 07:40:03,516] Trial 71 finished with value: 0.8467550796532064 and parameters: {'learning_rate': 0.029982510909413663, 'num_leaves': 301}. Best is trial 71 with value: 0.8467550796532064.\n",
            "[I 2024-11-12 07:45:46,488] Trial 72 finished with value: 0.8466760279798429 and parameters: {'learning_rate': 0.02983823346076994, 'num_leaves': 301}. Best is trial 71 with value: 0.8467550796532064.\n",
            "[I 2024-11-12 07:51:29,001] Trial 73 finished with value: 0.8468332324435714 and parameters: {'learning_rate': 0.029940932406444354, 'num_leaves': 301}. Best is trial 73 with value: 0.8468332324435714.\n",
            "[I 2024-11-12 07:57:11,459] Trial 74 finished with value: 0.8466608307548764 and parameters: {'learning_rate': 0.029953846332469405, 'num_leaves': 300}. Best is trial 73 with value: 0.8468332324435714.\n",
            "[I 2024-11-12 08:02:54,208] Trial 75 finished with value: 0.8465595077730255 and parameters: {'learning_rate': 0.0296970164388102, 'num_leaves': 303}. Best is trial 73 with value: 0.8468332324435714.\n",
            "[I 2024-11-12 08:08:36,795] Trial 76 finished with value: 0.8468116629866648 and parameters: {'learning_rate': 0.02999078079462655, 'num_leaves': 301}. Best is trial 73 with value: 0.8468332324435714.\n",
            "[I 2024-11-12 08:14:21,882] Trial 77 finished with value: 0.8467237556529144 and parameters: {'learning_rate': 0.029714360059771575, 'num_leaves': 308}. Best is trial 73 with value: 0.8468332324435714.\n",
            "[I 2024-11-12 08:20:07,475] Trial 78 finished with value: 0.8467677160219775 and parameters: {'learning_rate': 0.029901725271370555, 'num_leaves': 309}. Best is trial 73 with value: 0.8468332324435714.\n",
            "[I 2024-11-12 08:25:53,031] Trial 79 finished with value: 0.8468528927574279 and parameters: {'learning_rate': 0.02994132562066922, 'num_leaves': 310}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 08:31:40,290] Trial 80 finished with value: 0.8319940883530771 and parameters: {'learning_rate': 0.010671042061622248, 'num_leaves': 306}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 08:37:24,397] Trial 81 finished with value: 0.8467399641206356 and parameters: {'learning_rate': 0.029818288330031414, 'num_leaves': 309}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 08:43:11,321] Trial 82 finished with value: 0.8454336112654517 and parameters: {'learning_rate': 0.02726505813635712, 'num_leaves': 310}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 08:48:58,064] Trial 83 finished with value: 0.8453984666060235 and parameters: {'learning_rate': 0.027098279664424612, 'num_leaves': 310}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 08:54:40,459] Trial 84 finished with value: 0.8453762114047366 and parameters: {'learning_rate': 0.02742359698291972, 'num_leaves': 295}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:00:21,160] Trial 85 finished with value: 0.8465952388522492 and parameters: {'learning_rate': 0.029812673420689984, 'num_leaves': 291}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:05:57,840] Trial 86 finished with value: 0.8465387539984999 and parameters: {'learning_rate': 0.029953866142088458, 'num_leaves': 280}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:11:41,852] Trial 87 finished with value: 0.8446238173951961 and parameters: {'learning_rate': 0.02572000998492, 'num_leaves': 304}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:17:23,787] Trial 88 finished with value: 0.8450195250203552 and parameters: {'learning_rate': 0.026487773898745952, 'num_leaves': 295}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:23:02,673] Trial 89 finished with value: 0.8453173039556692 and parameters: {'learning_rate': 0.02755498028161299, 'num_leaves': 282}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:28:45,791] Trial 90 finished with value: 0.8350639878902653 and parameters: {'learning_rate': 0.01315603646355671, 'num_leaves': 291}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:34:28,090] Trial 91 finished with value: 0.8467075756168375 and parameters: {'learning_rate': 0.029942744319148965, 'num_leaves': 300}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:40:12,800] Trial 92 finished with value: 0.8468012973513698 and parameters: {'learning_rate': 0.0299996658203676, 'num_leaves': 305}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:45:57,830] Trial 93 finished with value: 0.8463012998384544 and parameters: {'learning_rate': 0.029114541557492365, 'num_leaves': 309}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:51:39,131] Trial 94 finished with value: 0.8460846745570029 and parameters: {'learning_rate': 0.028806733622099928, 'num_leaves': 295}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 09:57:23,583] Trial 95 finished with value: 0.8455019679495954 and parameters: {'learning_rate': 0.02761932097146664, 'num_leaves': 303}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:03:01,591] Trial 96 finished with value: 0.8460237718415907 and parameters: {'learning_rate': 0.028758560562539063, 'num_leaves': 286}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:07:16,107] Trial 97 finished with value: 0.8374316722176228 and parameters: {'learning_rate': 0.02672866382573624, 'num_leaves': 56}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:13:05,058] Trial 98 finished with value: 0.8467948575213728 and parameters: {'learning_rate': 0.029885263793850824, 'num_leaves': 310}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:18:50,047] Trial 99 finished with value: 0.844225875071851 and parameters: {'learning_rate': 0.025194905897499682, 'num_leaves': 295}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:24:40,292] Trial 100 finished with value: 0.8386193125588596 and parameters: {'learning_rate': 0.016500921678412994, 'num_leaves': 307}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:30:27,113] Trial 101 finished with value: 0.8468265215791295 and parameters: {'learning_rate': 0.029963335768763213, 'num_leaves': 310}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:36:08,934] Trial 102 finished with value: 0.8459845356860901 and parameters: {'learning_rate': 0.02865533013780969, 'num_leaves': 290}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:41:55,024] Trial 103 finished with value: 0.8464245219833378 and parameters: {'learning_rate': 0.02924221990206207, 'num_leaves': 306}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:45:49,905] Trial 104 finished with value: 0.8351217881583832 and parameters: {'learning_rate': 0.02804623400382547, 'num_leaves': 33}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:51:38,021] Trial 105 finished with value: 0.8455613967036409 and parameters: {'learning_rate': 0.027629713412427162, 'num_leaves': 310}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 10:57:17,674] Trial 106 finished with value: 0.8462024944632646 and parameters: {'learning_rate': 0.029282989956402935, 'num_leaves': 283}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 11:03:00,663] Trial 107 finished with value: 0.845968477384317 and parameters: {'learning_rate': 0.028599199949016538, 'num_leaves': 296}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 11:08:39,127] Trial 108 finished with value: 0.8462721334190973 and parameters: {'learning_rate': 0.029375652885376937, 'num_leaves': 279}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 11:14:24,660] Trial 109 finished with value: 0.8447390792237244 and parameters: {'learning_rate': 0.02598491822552254, 'num_leaves': 304}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 11:20:02,723] Trial 110 finished with value: 0.8454065373260766 and parameters: {'learning_rate': 0.027726602038445403, 'num_leaves': 291}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[I 2024-11-12 11:25:42,844] Trial 111 finished with value: 0.846676481208533 and parameters: {'learning_rate': 0.029756130634336644, 'num_leaves': 298}. Best is trial 79 with value: 0.8468528927574279.\n",
            "[W 2024-11-12 11:26:48,029] Trial 112 failed with parameters: {'learning_rate': 0.029931738635150997, 'num_leaves': 301} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Egor\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"C:\\Temp\\ipykernel_19176\\2705384631.py\", line 26, in objective\n",
            "    model.fit(x_train_1, y_train_1, eval_set=(x_valid_1, y_valid_1), eval_metric='auc')\n",
            "  File \"C:\\Users\\Egor\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1284, in fit\n",
            "    super().fit(\n",
            "  File \"C:\\Users\\Egor\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 955, in fit\n",
            "    self._Booster = train(\n",
            "                    ^^^^^^\n",
            "  File \"C:\\Users\\Egor\\anaconda3\\Lib\\site-packages\\lightgbm\\engine.py\", line 307, in train\n",
            "    booster.update(fobj=fobj)\n",
            "  File \"C:\\Users\\Egor\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py\", line 4136, in update\n",
            "    _LIB.LGBM_BoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2024-11-12 11:26:48,033] Trial 112 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[75], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m tpe_sampler \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m666\u001b[39m)\n\u001b[0;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mtpe_sampler)\n\u001b[1;32m----> 4\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[1;32mIn[73], line 26\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     22\u001b[0m y_train_1, y_valid_1 \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspace)\n\u001b[1;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train_1, y_train_1, eval_set\u001b[38;5;241m=\u001b[39m(x_valid_1, y_valid_1), eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m w\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mbest_score_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     29\u001b[0m best_iter\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mbest_iteration_)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1284\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1285\u001b[0m     X,\n\u001b[0;32m   1286\u001b[0m     _y,\n\u001b[0;32m   1287\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1288\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[0;32m   1289\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m   1290\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m   1291\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[0;32m   1292\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[0;32m   1293\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[0;32m   1294\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[0;32m   1295\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m   1296\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[0;32m   1297\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1298\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m   1299\u001b[0m )\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m    956\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    957\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[0;32m    958\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[0;32m    959\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m    960\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m    961\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m    963\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    964\u001b[0m )\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4135\u001b[0m _safe_call(\n\u001b[1;32m-> 4136\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[0;32m   4138\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished),\n\u001b[0;32m   4139\u001b[0m     )\n\u001b[0;32m   4140\u001b[0m )\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "nrounds=[]\n",
        "tpe_sampler = optuna.samplers.TPESampler(seed=666)\n",
        "study = optuna.create_study(direction='maximize', sampler=tpe_sampler)\n",
        "study.optimize(objective, n_trials=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как мы видим, optuna не смогла подобрать достойную конфигурацию модели, поэтому попробуем подобрать сами"
      ],
      "metadata": {
        "id": "zy6pihCO1Svp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning_rate возьмем от катбуста"
      ],
      "metadata": {
        "id": "PfZCKrZo1bAO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12xcaNuKyF73",
        "outputId": "fed054fe-240f-4a46-c9c8-bfe99a0871ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2638\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8623392081743037"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LGBMClassifier(device_type='gpu', n_estimators=16384, early_stopping_round=50, random_state=666, verbose=-1, num_leaves=75, learning_rate=0.016, min_data_in_leaf=3000)\n",
        "model.fit(x_train, y_train, eval_set=(x_valid, y_valid))\n",
        "print(model.best_iteration_)\n",
        "roc_auc_score(y_valid, model.predict_proba(x_valid)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzCozA0zyF74",
        "outputId": "f2ea4440-9976-45ef-b153-e8549346207c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5558\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8613304152771399"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LGBMClassifier(device_type='gpu', n_estimators=16384, early_stopping_round=50, random_state=666, verbose=-1, num_leaves=31, learning_rate=0.016, min_data_in_leaf=2500)\n",
        "model.fit(x_train, y_train, eval_set=(x_valid, y_valid))\n",
        "print(model.best_iteration_)\n",
        "roc_auc_score(y_valid, model.predict_proba(x_valid)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGRgkT7wyF74",
        "outputId": "d434bf96-c874-4bde-bd18-7b5775628b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2912\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8625205627579507"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LGBMClassifier(device_type='gpu', n_estimators=16384, early_stopping_round=50, random_state=666, verbose=-1, num_leaves=80, learning_rate=0.016, min_data_in_leaf=3000)\n",
        "model.fit(x_train, y_train, eval_set=(x_valid, y_valid))\n",
        "print(model.best_iteration_)\n",
        "roc_auc_score(y_valid, model.predict_proba(x_valid)[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHaT05U8yF74",
        "outputId": "63eac41d-5769-43ea-9846-6e07202e3d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3877\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8628110082141999"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = LGBMClassifier(device_type='gpu', n_estimators=16384, early_stopping_round=50, random_state=666, verbose=-1, num_leaves=80, learning_rate=0.016, min_data_in_leaf=4500)\n",
        "model.fit(x_train, y_train, eval_set=(x_valid, y_valid))\n",
        "print(model.best_iteration_)\n",
        "roc_auc_score(y_valid, model.predict_proba(x_valid)[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим лучшую конфигурацию на всех данных"
      ],
      "metadata": {
        "id": "uD_Xs0Ff1fKt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQ01_7sDyF74",
        "outputId": "3520e8c4-cd9f-4e9e-c1ce-62f285e7f8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "model = LGBMClassifier(device_type='gpu', n_estimators=3877, random_state=666, verbose=-1, num_leaves=80, learning_rate=0.016, min_data_in_leaf=4500)\n",
        "model.fit(train, y)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18dP7TrbyREl"
      },
      "source": [
        "# UPLOAD TEST AND PREDICT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим тестовые данные и сделаем сабмит"
      ],
      "metadata": {
        "id": "LPx6e-En1l54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbuKg_5eSjXx"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('test_1.csv', dtype=types_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2, 11):\n",
        "    test = pd.concat([test, pd.read_csv(f'test_{i}.csv', dtype=types_dict)])"
      ],
      "metadata": {
        "id": "8MX0fRm10YN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAegNFaQS3GJ"
      },
      "outputs": [],
      "source": [
        "submit = test[['id']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmQMfmWRS8O6"
      },
      "outputs": [],
      "source": [
        "test['feature_83'] =  test['feature_83'].apply(preprocess_83).astype('int8')\n",
        "test['feature_133'] = test['feature_133'].apply(preprocess_133).astype('int8')\n",
        "test['feature_201'] = test['feature_201'].apply(preprocess_201).astype('int8')\n",
        "test['feature_251'] = test['feature_251'].apply(preprocess_251).astype('int8')\n",
        "test['feature_253'] = test['feature_253'].apply(preprocess_253).astype('int8')\n",
        "test['feature_343'] = test['feature_343'].apply(preprocess_343).astype('int8')\n",
        "test['feature_382'] = test['feature_382'].apply(preprocess_382).astype('int8')\n",
        "test['feature_406'] = test['feature_406'].apply(preprocess_406).astype('int8')\n",
        "test['feature_423'] = test['feature_423'].apply(preprocess_423).astype('int8')\n",
        "test['feature_449'] = test['feature_449'].apply(preprocess_449).astype('int8')\n",
        "test['feature_490'] = test['feature_490'].apply(preprocess_490).astype('int8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29b8m15GS_Tw"
      },
      "outputs": [],
      "source": [
        "test = pd.get_dummies(test, columns=cat_features, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfzo_2zSTErU"
      },
      "outputs": [],
      "source": [
        "submit['target'] = model.predict_proba(test[x_valid.columns])[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Lgic_OwfUoFu",
        "outputId": "d29ab13d-1af5-4a95-82fe-7e4eca5a4a65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4490468</td>\n",
              "      <td>0.010243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4490469</td>\n",
              "      <td>0.012519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4490470</td>\n",
              "      <td>0.009356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4490471</td>\n",
              "      <td>0.077187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4490472</td>\n",
              "      <td>0.573810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509527</th>\n",
              "      <td>4999995</td>\n",
              "      <td>0.029924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509528</th>\n",
              "      <td>4999996</td>\n",
              "      <td>0.007762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509529</th>\n",
              "      <td>4999997</td>\n",
              "      <td>0.026947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509530</th>\n",
              "      <td>4999998</td>\n",
              "      <td>0.064388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509531</th>\n",
              "      <td>4999999</td>\n",
              "      <td>0.011822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>509532 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id    target\n",
              "0       4490468  0.010243\n",
              "1       4490469  0.012519\n",
              "2       4490470  0.009356\n",
              "3       4490471  0.077187\n",
              "4       4490472  0.573810\n",
              "...         ...       ...\n",
              "509527  4999995  0.029924\n",
              "509528  4999996  0.007762\n",
              "509529  4999997  0.026947\n",
              "509530  4999998  0.064388\n",
              "509531  4999999  0.011822\n",
              "\n",
              "[509532 rows x 2 columns]"
            ]
          },
          "execution_count": 149,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNkQ4mmIyF75"
      },
      "outputs": [],
      "source": [
        "submit.to_csv('lgbm_hand_tunned_12_11_2024.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "YJ9FVVxsyF74"
      },
      "source": [
        "# GENERATING PREDS ON TRAIN DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним предсказания модели по всем обучающим данным для стекинга"
      ],
      "metadata": {
        "id": "Wu_IhJoW1qUX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQJ-UUfvyF74"
      },
      "outputs": [],
      "source": [
        "train = train.reset_index(drop=True)\n",
        "train['id'] = train.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exCyfFNjyF74",
        "outputId": "f8046ecf-d19e-456c-8f5a-7f7c01010ccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1:\n",
            "validation roc auc: 0.8610893272760936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Temp\\ipykernel_19176\\821573114.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  lgbm_preds = pd.concat([lgbm_preds, scored_sample])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2:\n",
            "validation roc auc: 0.8611340408169285\n",
            "Fold 3:\n",
            "validation roc auc: 0.8586243276530678\n",
            "Fold 4:\n",
            "validation roc auc: 0.8620474942414846\n",
            "Fold 5:\n",
            "validation roc auc: 0.8616775472321131\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "lgbm_preds = pd.DataFrame(columns=['id', 'lgbm_85.9_proba'])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for i, (train_index, valid_index) in enumerate(skf.split(train, y)):\n",
        "\n",
        "    x_train, y_train = train.iloc[train_index, :], y.iloc[train_index]\n",
        "    x_valid, y_valid = train.iloc[valid_index, :], y.iloc[valid_index]\n",
        "\n",
        "    scored_sample = x_valid[['id']]\n",
        "\n",
        "    x_train = x_train.drop('id', axis=1)\n",
        "    x_valid = x_valid.drop('id', axis=1)\n",
        "\n",
        "    model = LGBMClassifier(device_type='gpu', n_estimators=2087, random_state=666, verbose=-1, num_leaves=75, learning_rate=0.016, min_data_in_leaf=3000)\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    #best_iter = model.best_iteration_\n",
        "    preds = model.predict_proba(x_valid)[:, 1]\n",
        "    valid_roc_auc = roc_auc_score(y_valid, preds)\n",
        "\n",
        "    print(f'Fold {i+1}:')\n",
        "    print(f'validation roc auc: {valid_roc_auc}')\n",
        "\n",
        "    scored_sample['lgbm_85.9_proba'] = preds\n",
        "    lgbm_preds = pd.concat([lgbm_preds, scored_sample])\n",
        "\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_preds.sort_values('id', ascending=True).to_csv('lgbm_85.9_train_preds.csv', index=False)"
      ],
      "metadata": {
        "id": "XMUDI4-R0ESR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}